import osos.chdir('[YOUR WORKING DIRECTORY]')os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'import torchimport torch.nn as nnimport torch.optim as optimfrom torch.utils.data import DataLoaderimport torchvisionimport My_Model as MMimport cv2import randomimport numpy as npfrom pathlib import Pathimport matplotlib.pyplot as plt#%% Pytorch versionprint(torch.__version__)print(torchvision.__version__)#%% Device agnostic codeif torch.backends.mps.is_available() & torch.backends.mps.is_built():    device = 'mps'else:    device = 'cpu'    print(device)#%% define some functionsdef my_sort(PATH):    LS = os.listdir(PATH)    LS.remove('.DS_Store')    LS.sort(key = lambda x: int(x.replace('.png', '')))    return LSdef train_val_test_split(D, train = 0.8, val = 0.1):    train_split = int(train * len(D))    val_split = int(val * len(D))    D_train = D[: train_split]    D_val = D[train_split : train_split + val_split]    D_test = D[train_split + val_split :]    return D_train, D_val, D_testdef my_data_loader1(PATH1, PATH2):    LS1 = my_sort(PATH1)  # 3000 samples for covid    LS2 = my_sort(PATH2)  # 3000 samples for non-covid    D = []    for i in range(len(LS1)):        '''         Dataset D is in a list format with each term is a tuple with        (feature, label) pair.             - feature: [3, 224, 224] - [channels, height, width]            - label: 1 for covid condition, 0 for non-covid condition        '''        # load the data        D1 = cv2.imread(PATH1 + LS1[i], cv2.IMREAD_GRAYSCALE)        D2 = cv2.imread(PATH2 + LS2[i], cv2.IMREAD_GRAYSCALE)        # reshape the data to 224 * 224        D1 = cv2.resize(D1, (224, 224), interpolation = cv2.INTER_LINEAR)        D2 = cv2.resize(D2, (224, 224), interpolation = cv2.INTER_LINEAR)        # Combine the data        D1 = np.repeat(D1[np.newaxis, :, :], 3, axis = 0)        D2 = np.repeat(D2[np.newaxis, :, :], 3, axis = 0)        D.append((D1, 1))  # covid code as 1        D.append((D2, 0))  # non-covid as 0    print('All data loaded successfully')    # visualize one example    plt.imshow(D[100][0][0, :, :], cmap = 'gray')    plt.show()    return Ddef my_data_loader2(PATH1, PATH2):    LS1 = my_sort(PATH1)  # 3000 samples for covid    LS2 = my_sort(PATH2)  # 3000 samples for non-covid    D = []    for i in range(len(LS1)):        '''         Dataset D is in a list format with each term is a tuple with        (feature, label) pair.             - feature: [3, 224, 224] - [channels, height, width]            - label: 1 for covid condition, 0 for non-covid condition        '''        # load the data        D1 = cv2.imread(PATH1 + LS1[i], cv2.IMREAD_GRAYSCALE)        D2 = cv2.imread(PATH2 + LS2[i], cv2.IMREAD_GRAYSCALE)        # reshape the data to 224 * 224        D1 = cv2.resize(D1, (224, 224), interpolation = cv2.INTER_LINEAR)        D2 = cv2.resize(D2, (224, 224), interpolation = cv2.INTER_LINEAR)        # Combine the data        D1 = np.repeat(D1[np.newaxis, :, :], 3, axis = 0)        D2 = np.repeat(D2[np.newaxis, :, :], 3, axis = 0)        D.append((D1, D2))  # (covid, non-covid)     print('All data loaded successfully')    # visualize one example    plt.subplot(1, 2, 1)    plt.imshow(D[0][0][0, :, :], cmap = 'gray')    plt.title('COVID')    plt.subplot(1, 2, 2)    plt.imshow(D[0][1][0, :, :], cmap = 'gray')    plt.title('NON_COVID')    plt.show()    return Ddef my_acc_fn(y_true, y_pred):    """Calculates accuracy between truth labels and predictions.    Args:        y_true (torch.Tensor): Truth labels for predictions.        y_pred (torch.Tensor): Predictions to be compared to predictions.    Returns:        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45    """    correct = torch.eq(y_true, y_pred).sum().item()    acc = (correct / len(y_pred)) * 100    return acc#%% Step 0: Data preprocessingYES_COVID_PATH = 'Data/YES_COVID/'NON_COVID_PATH = 'Data/NON_COVID/'# Obtain the dataD = my_data_loader1(YES_COVID_PATH, NON_COVID_PATH)# Shuffle the datarandom.seed(42)random.shuffle(D)# Split dataD_train, D_val, D_test = train_val_test_split(D)print(f'Trainset length: {len(D_train)} | Valset length: {len(D_val)} | Testset length: {len(D_test)}')# Put training dataset into dataloaderBATCH_SIZE = 16train_dataloader = DataLoader(dataset = D_train,                              batch_size = BATCH_SIZE,                              shuffle = True)# Check out the dataloaderprint('Length of the train Dataloader: {} batch.'.format(len(train_dataloader)))f, l = next(iter(train_dataloader))print(f'Train batch feature shape: {f.shape}; Train batch label shape: {l.shape}')# Turn valset and testset into tensorsD_train = [(torch.tensor(X).type(torch.float), torch.tensor(y).type(torch.LongTensor)) for X, y in D_train]D_val = [(torch.tensor(X).type(torch.float), torch.tensor(y).type(torch.LongTensor)) for X, y in D_val]D_test = [(torch.tensor(X).type(torch.float), torch.tensor(y).type(torch.LongTensor)) for X, y in D_test]print(f'validation set data type: {type(D_val[0][0])} |  test set data type: {type(D_test[0][0])}')#%% Step 1: train the classification model (fine-tuning the Resnet18)''' Instantiate model '''cls_model = MM.COVIDNet(num_classes = 2).to(device)''' Define the optimizer and the loss function '''optimizer = optim.Adam(cls_model.parameters(), lr = 1e-5)loss_fn = nn.CrossEntropyLoss()''' Start the training and testing loop '''torch.manual_seed(42)epochs = 5TRAIN_LOSS, TRAIN_ACC, VAL_LOSS, VAL_ACC = [], [], [], []for epoch in range(epochs):    # if epoch % 5 == 0:    print(f'Epoch: {epoch}\n-----------------')    ### Training    train_acc, train_loss = 0, 0    for batch, (X, y) in enumerate(train_dataloader):        # Set model in training mode        cls_model.train()        # put data to GPU        X, y = X.type(torch.float).to(device), y.to(device)        # forward pass        y_pred = cls_model(X)        # caculate loss        acc = my_acc_fn(y, y_pred.argmax(dim = 1))        train_acc += acc        loss = loss_fn(y_pred, y)        train_loss += loss        # optimizer zero grad        optimizer.zero_grad()        # loss backward        loss.backward()        # optimizer step        optimizer.step()    train_loss /= len(train_dataloader)    train_acc /= len(train_dataloader)    TRAIN_LOSS.append(train_loss)    TRAIN_ACC.append(train_acc)        ### Validation    val_acc, val_loss = 0, 0    cls_model.eval()    correct = 0    with torch.inference_mode():        for X, y in D_val:            X = X[np.newaxis, :, :, :].to(device)            y = y.to(device)            y_pred = cls_model(X).squeeze()            val_loss += loss_fn(y_pred, y)            y_pred = y_pred.argmax()            correct = correct + 1 if y_pred == y else correct        val_loss /= len(D_val)        val_acc = correct / len(D_val)        VAL_LOSS.append(val_loss)        VAL_ACC.append(val_acc)        # if epoch % 5 == 0:    print(f'Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Val loss: {val_loss:.4f} | Val acc: {val_acc:.4f}.\n')''' Save the model '''# Create model directoryMODEL_PATH = Path('Models')MODEL_PATH.mkdir(parents = True, exist_ok = True)# Create model save pathMODEL_NAME = 'cls_model_v1.pth'MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME# Save the model state_dictprint('saving model to: {}'.format(MODEL_SAVE_PATH))torch.save(obj = cls_model.state_dict(),           f = MODEL_SAVE_PATH)#%% Step 2: train the warping model''' Load the classification model '''MODEL_SAVE_PATH = 'Models/cls_model_v1.pth'cls_model = MM.COVIDNet()  # instantiate a new instance of our model classcls_model.load_state_dict(torch.load(f = MODEL_SAVE_PATH))cls_model.to(device).eval()''' Load data separately '''YES_COVID_PATH = 'Data/YES_COVID/'NON_COVID_PATH = 'Data/NON_COVID/'# load dataD = my_data_loader2(YES_COVID_PATH, NON_COVID_PATH)D_train = D[: int(0.8 * len(D))]D_test = D[int(0.8 * len(D)) :]# Put training dataset into dataloaderBATCH_SIZE = 8D_train_dataloader = DataLoader(dataset = D_train,                                batch_size = BATCH_SIZE,                                shuffle = True)D_test_dataloader = DataLoader(dataset = D_test,                               batch_size = BATCH_SIZE,                               shuffle = True)''' Instantiate model '''forward = MM.WARP_Model_tmp1()backward = MM.WARP_Model_tmp1()sim_model = MM.WARP_Model(forward, backward).to(device)''' Define the optimizer and the loss function '''optimizer = optim.Adam(sim_model.parameters(), lr = 1e-3)loss_fn = MM.warp_loss()''' Start the training and testing loop '''torch.manual_seed(42)epochs = 20TRAIN_LOSS, TEST_LOSS = [], []for epoch in range(epochs):    # if epoch % 5 == 0:    print(f'Epoch: {epoch}\n-----------------')    ### Training    train_loss = 0    for batch, (X, Y) in enumerate(D_train_dataloader):        # Set model in training mode        sim_model.train()        # put data to GPU        X, Y = X.type(torch.float).to(device), Y.type(torch.float).to(device)        # forward pass        X_hat, X_hat_vec_field, X_tilda, X_tilda_vec_field = sim_model(X)        X_logit = cls_model(X)        X_hat_logit = cls_model(X_hat)        X_tilda_logit = cls_model(X_tilda)        Y_logit = cls_model(Y)        # caculate loss        loss = loss_fn(X, X_hat, X_tilda, Y,                       X_logit, X_hat_logit, X_tilda_logit, Y_logit,                       X_hat_vec_field, X_tilda_vec_field)        train_loss += loss        # optimizer zero grad        optimizer.zero_grad()        # loss backward        loss.backward()        # optimizer step        optimizer.step()    train_loss /= len(D_train_dataloader)    TRAIN_LOSS.append(train_loss)        ### Testing    test_loss = 0    sim_model.eval()    with torch.inference_mode():        for batch, (X, Y) in enumerate(D_test_dataloader):            # Set model in training mode            sim_model.train()            # put data to GPU            X, Y = X.type(torch.float).to(device), Y.type(torch.float).to(device)            # forward pass            X_hat, X_hat_vec_field, X_tilda, X_tilda_vec_field = sim_model(X)            X_logit = cls_model(X)            X_hat_logit = cls_model(X_hat)            X_tilda_logit = cls_model(X_tilda)            Y_logit = cls_model(Y)            # caculate loss            loss = loss_fn(X, X_hat, X_tilda, Y,                           X_logit, X_hat_logit, X_tilda_logit, Y_logit,                           X_hat_vec_field, X_tilda_vec_field)            test_loss += loss        test_loss /= len(D_test_dataloader)        TEST_LOSS.append(test_loss)    print(f'Train loss: {train_loss:.4f} | Test loss: {test_loss:.4f}.\n')TRAIN_LOSS = [i.cpu().detach().numpy() for i in TRAIN_LOSS]TEST_LOSS = [i.cpu().detach().numpy() for i in TEST_LOSS]#%% Visualization 1X_hat_vec_field_total, X_tilda_vec_field_total = torch.zeros((1, 1, 224, 224)).to(device), torch.zeros((1, 1, 224, 224)).to(device)with torch.inference_mode():    for X, Y in D_test:        sim_model.eval()        # put data to GPU        X, Y = torch.tensor(X[np.newaxis, :, :, :]), torch.tensor(Y[np.newaxis, :, :, :])        X, Y = X.type(torch.float).to(device), Y.type(torch.float).to(device)        # forward pass        X_hat, X_hat_vec_field, X_tilda, X_tilda_vec_field = sim_model(X)        X_hat_vec_field_total += X_hat_vec_field        X_tilda_vec_field_total += X_tilda_vec_fieldX_hat_vec_field_total /= len(D_test)X_tilda_vec_field_total /= len(D_test)fig = plt.figure(figsize = (12, 6))ax1 = plt.subplot(1, 2, 1)ax1 = plt.imshow(X_hat_vec_field_total[0, 0, :, :].cpu(), cmap = 'gray')ax1 = plt.title('Covid -> Non Covid', fontsize = 25)ax1 = plt.axis(False)ax2 = plt.subplot(1, 2, 2)ax2 = plt.imshow(X_tilda_vec_field_total[0, 0, :, :].cpu(), cmap = 'gray')ax2 = plt.title('Non Covid -> Covid', fontsize = 25)ax2 = plt.axis(False)fig.tight_layout()plt.savefig('Results/I2I_average_result.png', bbox_inches = 'tight', dpi = 300)#%% Visualization 2n = 9X, Y = D_test[n][0], D_test[n][1]sim_model.eval()# put data to GPUX, Y = torch.tensor(X[np.newaxis, :, :, :]), torch.tensor(Y[np.newaxis, :, :, :])X, Y = X.type(torch.float).to(device), Y.type(torch.float).to(device)# forward passX_hat, X_hat_vec_field, X_tilda, X_tilda_vec_field = sim_model(X)fig = plt.figure(figsize = (12, 18))plt.subplot(3, 2, 1)plt.imshow(X[0, 0, :, :].cpu(), cmap = 'gray')plt.title('Img X', fontsize = 25)plt.axis(False)plt.subplot(3, 2, 2)plt.imshow(X_hat[0, 0, :, :].cpu().detach().numpy(), cmap = 'gray')plt.title('Img X_hat', fontsize = 25)plt.axis(False)plt.subplot(3, 2, 3)plt.imshow(X_tilda[0, 0, :, :].cpu().detach().numpy(), cmap = 'gray')plt.title('Img X_tilda', fontsize = 25)plt.axis(False)plt.subplot(3, 2, 4)plt.imshow(Y[0, 0, :, :].cpu(), cmap = 'gray')plt.title('Img Y', fontsize = 25)plt.axis(False)plt.subplot(3, 2, 5)plt.imshow(X_hat_vec_field[0, 0, :, :].cpu().detach().numpy(), cmap = 'gray')plt.title('X_hat_vec_field (x -> x_hat)', fontsize = 25)plt.axis(False)plt.subplot(3, 2, 6)plt.imshow(X_tilda_vec_field[0, 0, :, :].cpu().detach().numpy(), cmap = 'gray')plt.title('X_tilda_vec_field (x_hat -> x_tilda)', fontsize = 25)plt.axis(False)fig.tight_layout()plt.savefig('Results/I2I_example2.png', bbox_inches = 'tight', dpi = 300)#%% Visualization 3fig = plt.figure(figsize = (10, 5))x = [i + 1 for i in range(len(TRAIN_LOSS))]plt.plot(x, TRAIN_LOSS, label = 'train loss', lw = 2)plt.plot(x, TEST_LOSS, label = 'test loss', lw = 2)plt.xlabel('number of epoch', fontsize = 25)plt.ylabel('loss', fontsize = 25)plt.xticks([5, 10, 15, 20], fontsize = 25)plt.yticks(fontsize = 25)plt.legend(fontsize = 25)fig.tight_layout()plt.savefig('Results/train-test loss.png', bbox_inches = 'tight', dpi = 300)